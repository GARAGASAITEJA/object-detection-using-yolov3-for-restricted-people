{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9119e841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "layer     filters    size              input                output\n",
      "    0 conv     32  3 x 3 / 1   416 x 416 x   3   ->   416 x 416 x  32\n",
      "    1 conv     64  3 x 3 / 2   416 x 416 x  32   ->   208 x 208 x  64\n",
      "    2 conv     32  1 x 1 / 1   208 x 208 x  64   ->   208 x 208 x  32\n",
      "    3 conv     64  3 x 3 / 1   208 x 208 x  32   ->   208 x 208 x  64\n",
      "    4 shortcut 1\n",
      "    5 conv    128  3 x 3 / 2   208 x 208 x  64   ->   104 x 104 x 128\n",
      "    6 conv     64  1 x 1 / 1   104 x 104 x 128   ->   104 x 104 x  64\n",
      "    7 conv    128  3 x 3 / 1   104 x 104 x  64   ->   104 x 104 x 128\n",
      "    8 shortcut 5\n",
      "    9 conv     64  1 x 1 / 1   104 x 104 x 128   ->   104 x 104 x  64\n",
      "   10 conv    128  3 x 3 / 1   104 x 104 x  64   ->   104 x 104 x 128\n",
      "   11 shortcut 8\n",
      "   12 conv    256  3 x 3 / 2   104 x 104 x 128   ->    52 x  52 x 256\n",
      "   13 conv    128  1 x 1 / 1    52 x  52 x 256   ->    52 x  52 x 128\n",
      "   14 conv    256  3 x 3 / 1    52 x  52 x 128   ->    52 x  52 x 256\n",
      "   15 shortcut 12\n",
      "   16 conv    128  1 x 1 / 1    52 x  52 x 256   ->    52 x  52 x 128\n",
      "   17 conv    256  3 x 3 / 1    52 x  52 x 128   ->    52 x  52 x 256\n",
      "   18 shortcut 15\n",
      "   19 conv    128  1 x 1 / 1    52 x  52 x 256   ->    52 x  52 x 128\n",
      "   20 conv    256  3 x 3 / 1    52 x  52 x 128   ->    52 x  52 x 256\n",
      "   21 shortcut 18\n",
      "   22 conv    128  1 x 1 / 1    52 x  52 x 256   ->    52 x  52 x 128\n",
      "   23 conv    256  3 x 3 / 1    52 x  52 x 128   ->    52 x  52 x 256\n",
      "   24 shortcut 21\n",
      "   25 conv    128  1 x 1 / 1    52 x  52 x 256   ->    52 x  52 x 128\n",
      "   26 conv    256  3 x 3 / 1    52 x  52 x 128   ->    52 x  52 x 256\n",
      "   27 shortcut 24\n",
      "   28 conv    128  1 x 1 / 1    52 x  52 x 256   ->    52 x  52 x 128\n",
      "   29 conv    256  3 x 3 / 1    52 x  52 x 128   ->    52 x  52 x 256\n",
      "   30 shortcut 27\n",
      "   31 conv    128  1 x 1 / 1    52 x  52 x 256   ->    52 x  52 x 128\n",
      "   32 conv    256  3 x 3 / 1    52 x  52 x 128   ->    52 x  52 x 256\n",
      "   33 shortcut 30\n",
      "   34 conv    128  1 x 1 / 1    52 x  52 x 256   ->    52 x  52 x 128\n",
      "   35 conv    256  3 x 3 / 1    52 x  52 x 128   ->    52 x  52 x 256\n",
      "   36 shortcut 33\n",
      "   37 conv    512  3 x 3 / 2    52 x  52 x 256   ->    26 x  26 x 512\n",
      "   38 conv    256  1 x 1 / 1    26 x  26 x 512   ->    26 x  26 x 256\n",
      "   39 conv    512  3 x 3 / 1    26 x  26 x 256   ->    26 x  26 x 512\n",
      "   40 shortcut 37\n",
      "   41 conv    256  1 x 1 / 1    26 x  26 x 512   ->    26 x  26 x 256\n",
      "   42 conv    512  3 x 3 / 1    26 x  26 x 256   ->    26 x  26 x 512\n",
      "   43 shortcut 40\n",
      "   44 conv    256  1 x 1 / 1    26 x  26 x 512   ->    26 x  26 x 256\n",
      "   45 conv    512  3 x 3 / 1    26 x  26 x 256   ->    26 x  26 x 512\n",
      "   46 shortcut 43\n",
      "   47 conv    256  1 x 1 / 1    26 x  26 x 512   ->    26 x  26 x 256\n",
      "   48 conv    512  3 x 3 / 1    26 x  26 x 256   ->    26 x  26 x 512\n",
      "   49 shortcut 46\n",
      "   50 conv    256  1 x 1 / 1    26 x  26 x 512   ->    26 x  26 x 256\n",
      "   51 conv    512  3 x 3 / 1    26 x  26 x 256   ->    26 x  26 x 512\n",
      "   52 shortcut 49\n",
      "   53 conv    256  1 x 1 / 1    26 x  26 x 512   ->    26 x  26 x 256\n",
      "   54 conv    512  3 x 3 / 1    26 x  26 x 256   ->    26 x  26 x 512\n",
      "   55 shortcut 52\n",
      "   56 conv    256  1 x 1 / 1    26 x  26 x 512   ->    26 x  26 x 256\n",
      "   57 conv    512  3 x 3 / 1    26 x  26 x 256   ->    26 x  26 x 512\n",
      "   58 shortcut 55\n",
      "   59 conv    256  1 x 1 / 1    26 x  26 x 512   ->    26 x  26 x 256\n",
      "   60 conv    512  3 x 3 / 1    26 x  26 x 256   ->    26 x  26 x 512\n",
      "   61 shortcut 58\n",
      "   62 conv   1024  3 x 3 / 2    26 x  26 x 512   ->    13 x  13 x1024\n",
      "   63 conv    512  1 x 1 / 1    13 x  13 x1024   ->    13 x  13 x 512\n",
      "   64 conv   1024  3 x 3 / 1    13 x  13 x 512   ->    13 x  13 x1024\n",
      "   65 shortcut 62\n",
      "   66 conv    512  1 x 1 / 1    13 x  13 x1024   ->    13 x  13 x 512\n",
      "   67 conv   1024  3 x 3 / 1    13 x  13 x 512   ->    13 x  13 x1024\n",
      "   68 shortcut 65\n",
      "   69 conv    512  1 x 1 / 1    13 x  13 x1024   ->    13 x  13 x 512\n",
      "   70 conv   1024  3 x 3 / 1    13 x  13 x 512   ->    13 x  13 x1024\n",
      "   71 shortcut 68\n",
      "   72 conv    512  1 x 1 / 1    13 x  13 x1024   ->    13 x  13 x 512\n",
      "   73 conv   1024  3 x 3 / 1    13 x  13 x 512   ->    13 x  13 x1024\n",
      "   74 shortcut 71\n",
      "   75 conv    512  1 x 1 / 1    13 x  13 x1024   ->    13 x  13 x 512\n",
      "   76 conv   1024  3 x 3 / 1    13 x  13 x 512   ->    13 x  13 x1024\n",
      "   77 conv    512  1 x 1 / 1    13 x  13 x1024   ->    13 x  13 x 512\n",
      "   78 conv   1024  3 x 3 / 1    13 x  13 x 512   ->    13 x  13 x1024\n",
      "   79 conv    512  1 x 1 / 1    13 x  13 x1024   ->    13 x  13 x 512\n",
      "   80 conv   1024  3 x 3 / 1    13 x  13 x 512   ->    13 x  13 x1024\n",
      "   81 conv    255  1 x 1 / 1    13 x  13 x1024   ->    13 x  13 x 255\n",
      "   82 detection\n",
      "   83 route  79\n",
      "   84 conv    256  1 x 1 / 1    13 x  13 x 512   ->    13 x  13 x 256\n",
      "   85 upsample           * 2    13 x  13 x 256   ->    26 x  26 x 256\n",
      "   86 route  85 61\n",
      "   87 conv    256  1 x 1 / 1    26 x  26 x 768   ->    26 x  26 x 256\n",
      "   88 conv    512  3 x 3 / 1    26 x  26 x 256   ->    26 x  26 x 512\n",
      "   89 conv    256  1 x 1 / 1    26 x  26 x 512   ->    26 x  26 x 256\n",
      "   90 conv    512  3 x 3 / 1    26 x  26 x 256   ->    26 x  26 x 512\n",
      "   91 conv    256  1 x 1 / 1    26 x  26 x 512   ->    26 x  26 x 256\n",
      "   92 conv    512  3 x 3 / 1    26 x  26 x 256   ->    26 x  26 x 512\n",
      "   93 conv    255  1 x 1 / 1    26 x  26 x 512   ->    26 x  26 x 255\n",
      "   94 detection\n",
      "   95 route  91\n",
      "   96 conv    128  1 x 1 / 1    26 x  26 x 256   ->    26 x  26 x 128\n",
      "   97 upsample           * 2    26 x  26 x 128   ->    52 x  52 x 128\n",
      "   98 route  97 36\n",
      "   99 conv    128  1 x 1 / 1    52 x  52 x 384   ->    52 x  52 x 128\n",
      "  100 conv    256  3 x 3 / 1    52 x  52 x 128   ->    52 x  52 x 256\n",
      "  101 conv    128  1 x 1 / 1    52 x  52 x 256   ->    52 x  52 x 128\n",
      "  102 conv    256  3 x 3 / 1    52 x  52 x 128   ->    52 x  52 x 256\n",
      "  103 conv    128  1 x 1 / 1    52 x  52 x 256   ->    52 x  52 x 128\n",
      "  104 conv    256  3 x 3 / 1    52 x  52 x 128   ->    52 x  52 x 256\n",
      "  105 conv    255  1 x 1 / 1    52 x  52 x 256   ->    52 x  52 x 255\n",
      "  106 detection\n"
     ]
    },
    {
     "ename": "Error",
     "evalue": "Canceled future for execute_request message before replies were done",
     "output_type": "error",
     "traceback": [
      "Error: Canceled future for execute_request message before replies were done",
      "at t.KernelShellFutureHandler.dispose (c:\\Users\\Saiteja\\.vscode\\extensions\\ms-toolsai.jupyter-2022.3.1000901801\\out\\extension.js:2:1204175)",
      "at c:\\Users\\Saiteja\\.vscode\\extensions\\ms-toolsai.jupyter-2022.3.1000901801\\out\\extension.js:2:1223227",
      "at Map.forEach (<anonymous>)",
      "at v._clearKernelState (c:\\Users\\Saiteja\\.vscode\\extensions\\ms-toolsai.jupyter-2022.3.1000901801\\out\\extension.js:2:1223212)",
      "at v.dispose (c:\\Users\\Saiteja\\.vscode\\extensions\\ms-toolsai.jupyter-2022.3.1000901801\\out\\extension.js:2:1216694)",
      "at c:\\Users\\Saiteja\\.vscode\\extensions\\ms-toolsai.jupyter-2022.3.1000901801\\out\\extension.js:2:533674",
      "at t.swallowExceptions (c:\\Users\\Saiteja\\.vscode\\extensions\\ms-toolsai.jupyter-2022.3.1000901801\\out\\extension.js:2:913059)",
      "at dispose (c:\\Users\\Saiteja\\.vscode\\extensions\\ms-toolsai.jupyter-2022.3.1000901801\\out\\extension.js:2:533652)",
      "at t.RawSession.dispose (c:\\Users\\Saiteja\\.vscode\\extensions\\ms-toolsai.jupyter-2022.3.1000901801\\out\\extension.js:2:537330)",
      "at runMicrotasks (<anonymous>)",
      "at processTicksAndRejections (node:internal/process/task_queues:96:5)"
     ]
    }
   ],
   "source": [
    "import cv2 #load our images\n",
    "import matplotlib.pyplot as plt #plot them,\n",
    "\n",
    "from utils import *  #module that contains some helper functions\n",
    "from darknet import Darknet #modified version of *Darknet*. YOLO uses *Darknet*,an open source, deep neural network framework written by the creators of YOLO. \n",
    "\n",
    "# Set the location and name of the cfg file that contains the network architecture\n",
    "cfg_file = 'C://Users//Saiteja//Desktop//New folder//Object-detection-using-YOLOv3//cfg//yolov3.cfg'\n",
    "\n",
    "# Set the location and name of the pre-trained weights file that contains the pre-trained weights\n",
    "weight_file = 'C://Users//Saiteja//Desktop//New folder//Object-detection-using-YOLOv3//weights//yolov3.weights'\n",
    "\n",
    "# Set the location and name of COCO object classes file that has the list of the 80 object classes that the weights were trained to detect.\n",
    "namesfile = 'C://Users//Saiteja//Desktop//New folder//Object-detection-using-YOLOv3//data//coco.names'\n",
    "\n",
    "# Load the network architecture\n",
    "m = Darknet(cfg_file)\n",
    "\n",
    "# Load the pre-trained weights\n",
    "m.load_weights(weight_file)\n",
    "\n",
    "# Load the COCO object classes\n",
    "class_names = load_class_names(namesfile)\n",
    "# Print the neural network used in YOLOv3\n",
    "m.print_network()\n",
    "\n",
    "# Set the default figure size\n",
    "plt.rcParams['figure.figsize'] = [24.0, 14.0]\n",
    "\n",
    "# load our images using OpenCV's cv2.imread() function.\n",
    "img = cv2.imread('./images/city_scene.jpg')\n",
    "\n",
    "# #Since, this function loads images as BGR we will convert our images to RGB\n",
    "original_image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# We resize the image to the input width and height of the first layer of the network ie 416 x 416 x 3.    \n",
    "resized_image = cv2.resize(original_image, (m.width, m.height))\n",
    "\n",
    "# Display the images\n",
    "plt.subplot(121)\n",
    "plt.title('Original Image')\n",
    "plt.imshow(original_image)\n",
    "plt.subplot(122)\n",
    "plt.title('Resized Image')\n",
    "plt.imshow(resized_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f55ae36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the NMS threshold\n",
    "nms_thresh = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4c9d315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the IOU threshold\n",
    "iou_thresh = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ea5c76c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'detect_objects' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7400/3071676801.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Detect objects in the image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mboxes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetect_objects\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresized_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miou_thresh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnms_thresh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Print the objects found and the confidence level\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint_objects\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'detect_objects' is not defined"
     ]
    }
   ],
   "source": [
    "# Detect objects in the image\n",
    "boxes = detect_objects(m, resized_image, iou_thresh, nms_thresh)\n",
    "\n",
    "# Print the objects found and the confidence level\n",
    "print_objects(boxes, class_names)\n",
    "\n",
    "#Plot the image with bounding boxes and corresponding object class labels\n",
    "plot_boxes(original_image, boxes, class_names, plot_labels = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938c6de4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
